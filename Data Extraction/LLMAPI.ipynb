{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directions\n",
    "Log in at <https://aiproxy.sanand.workers.dev/> with your IITM email ID to get your AIPROXY_TOKEN.\n",
    "\n",
    "Then, instead of sending an API request to `https://api.openai.com/`:\n",
    "\n",
    "- Replace `https://api.openai.com/` with `https://aiproxy.sanand.workers.dev/openai/`\n",
    "- Replace the OPENAI_API_KEY with the AIPROXY_TOKEN\n",
    "\n",
    "For example:\n",
    "\n",
    "```shell\n",
    "curl -X POST http://aiproxy.sanand.workers.dev/openai/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $AIPROXY_TOKEN\" \\\n",
    "  -d '{\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"user\", \"content\": \"What is 2 + 2\"}]}'\n",
    "\n",
    "curl -X POST http://aiproxy.sanand.workers.dev/openai/v1/embeddings \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $AIPROXY_TOKEN\" \\\n",
    "  -d '{\"model\": \"text-embedding-3-small\", \"input\": [\"king\", \"queen\"]}'\n",
    "```\n",
    "\n",
    "AI Proxy only supports these endpoints and models:\n",
    "\n",
    "- `GET https://aiproxy.sanand.workers.dev/openai/v1/models`\n",
    "- `POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings`\n",
    "  - `model: text-embedding-3-small`\n",
    "- `POST https://aiproxy.sanand.workers.dev/openai/v1/chat/completions`\n",
    "  - `model: gpt-4o-mini`\n",
    "\n",
    "It returns a set of additional headers:\n",
    "\n",
    "1. `cost`: Cost of this request in USD\n",
    "2. `monthlyCost`: Total costs (in USD) of requests used this month. Monthly limit is $0.5 (resets at midnight UTC on the first of the next month).\n",
    "3. `monthlyRequests`: Total requests made this month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AIProxy token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIPROXY_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "sysprompt = ''\n",
    "usrprompt = ''\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {AIPROXY_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": usrprompt}\n",
    "    ],\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    data=json.dumps(data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Embeddings (example sentence similarity code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# Read the text file and extract sentences\n",
    "with open(\"your_text_file.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# API endpoint and headers\n",
    "url = \"https://aiproxy.sanand.workers.dev/openai/v1/embeddings\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {AIPROXY_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Prepare API request payload\n",
    "payload = {\n",
    "    \"model\": \"text-embedding-3-small\",\n",
    "    \"input\": sentences,\n",
    "    \"encoding_format\": \"float\"\n",
    "}\n",
    "\n",
    "# Send request to OpenAI API\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "# Parse response\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    embeddings = [entry[\"embedding\"] for entry in response_data[\"data\"]]\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Find similar sentence pairs (cosine similarity > threshold)\n",
    "threshold = 0.85  # Adjust as needed\n",
    "similar_pairs = []\n",
    "for (i, j) in itertools.combinations(range(len(sentences)), 2):\n",
    "    similarity = cosine_similarity(embeddings[i], embeddings[j])\n",
    "    if similarity > threshold:\n",
    "        similar_pairs.append((sentences[i], sentences[j], similarity))\n",
    "\n",
    "# Print similar sentence pairs\n",
    "for sent1, sent2, score in similar_pairs:\n",
    "    print(f\"Similarity: {score:.2f}\\nSentence 1: {sent1}\\nSentence 2: {sent2}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
